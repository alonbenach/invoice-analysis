{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82a510cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root on sys.path: /home/alonbenach/project/invoice-analysis\n",
      "Notebook cwd: /home/alonbenach/project/invoice-analysis/notebooks\n",
      "Root children: ['.git', 'outputs', 'data', 'src', 'config', 'outputs_large', 'notebooks', 'balagan']\n"
     ]
    }
   ],
   "source": [
    "# setting up the project root on sys.path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root on sys.path:\", PROJECT_ROOT)\n",
    "print(\"Notebook cwd:\", Path.cwd())\n",
    "print(\"Root children:\", [p.name for p in PROJECT_ROOT.iterdir() if p.is_dir()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550de232",
   "metadata": {},
   "source": [
    "ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40dd16a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from src.io_utils import list_csvs, read_csv, write_parquet, ensure_dir\n",
    "from src.clean_utils import normalize_columns, parse_timestamp, assign_slots, cast_basic_types, basic_checks\n",
    "from src.viz_utils import save_bar, save_hist, save_box\n",
    "\n",
    "from src.fc_map_utils import map_fc_products, normalize_text\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2aff82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Paths\n",
    "# IMPORTANT: use project-root-relative paths\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"invoices\"\n",
    "DATA_FILE = DATA_DIR / \"invoices_09_2025.csv\"\n",
    "OUT_DIR  = PROJECT_ROOT / \"outputs_large\" / \"audit\"\n",
    "PLOTS    = OUT_DIR / \"plots\"\n",
    "CFG_SLOTS = PROJECT_ROOT / \"config\" / \"slots.yaml\"\n",
    "CFG_FC_TH = PROJECT_ROOT / \"config\" / \"fc_mapping_threshold.yaml\"\n",
    "\n",
    "ensure_dir(OUT_DIR); ensure_dir(PLOTS)\n",
    "pd.options.display.max_columns = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b14daef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 260,000 from: ['invoices_09_2025.csv']\n"
     ]
    }
   ],
   "source": [
    "# 2 load files\n",
    "if DATA_FILE.exists():\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_FILE, sep=\",\", encoding=\"utf-8\", low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(DATA_FILE, sep=\",\", encoding=\"cp1250\", low_memory=False)\n",
    "    raw_sources = [DATA_FILE.name]\n",
    "else:\n",
    "    # fallback to old behaviour if needed\n",
    "    csvs = list_csvs(DATA_DIR)\n",
    "    dfs = [read_csv(p) for p in csvs]\n",
    "    df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "    raw_sources = [p.name for p in csvs]\n",
    "\n",
    "print(f\"Loaded rows: {len(df):,} from: {raw_sources}\")\n",
    "pd.Series(raw_sources).to_csv(OUT_DIR/\"_file_list.csv\", index=False, header=[\"file\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "adfec2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Numer_paragonu', 'EAN', 'Rabat', 'Kasjer', 'Metoda_platnosci', 'Stawka_VAT', 'Siec_sklepow']\n",
      "Rows: 260,000\n",
      "Raw columns: ['ID_Paragonu', 'Data_zakupu', 'Godzina_zakupu', 'Linia_produktowa', 'Nazwa_produktu', 'Ilosc', 'Cena_jednostkowa_brutto', 'Cena_jednostkowa_netto']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID_Paragonu",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Data_zakupu",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Godzina_zakupu",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Linia_produktowa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nazwa_produktu",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Ilosc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cena_jednostkowa_brutto",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cena_jednostkowa_netto",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "00296e1d-a2b8-4210-8944-4de721a3cc16",
       "rows": [
        [
         "0",
         "31006967",
         "2025-09-01",
         "07:07",
         "KAJZERKA xxl 95g-C",
         null,
         "2.0",
         "0.79",
         "0.75"
        ],
        [
         "1",
         "31006967",
         "2025-09-01",
         "07:07",
         "SER TOPIONY TOST PLASTRY 130g-C",
         "Sertop Tychy Ser topiony w plastrach tost 130 g (8 sztuk) ",
         "1.0",
         "6.4",
         "6.1"
        ],
        [
         "2",
         "31006967",
         "2025-09-01",
         "07:07",
         "CHLEB TOST PELNOZ-C",
         null,
         "1.0",
         "4.99",
         "4.75"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Paragonu</th>\n",
       "      <th>Data_zakupu</th>\n",
       "      <th>Godzina_zakupu</th>\n",
       "      <th>Linia_produktowa</th>\n",
       "      <th>Nazwa_produktu</th>\n",
       "      <th>Ilosc</th>\n",
       "      <th>Cena_jednostkowa_brutto</th>\n",
       "      <th>Cena_jednostkowa_netto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31006967</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>07:07</td>\n",
       "      <td>KAJZERKA xxl 95g-C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31006967</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>07:07</td>\n",
       "      <td>SER TOPIONY TOST PLASTRY 130g-C</td>\n",
       "      <td>Sertop Tychy Ser topiony w plastrach tost 130 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31006967</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>07:07</td>\n",
       "      <td>CHLEB TOST PELNOZ-C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_Paragonu Data_zakupu Godzina_zakupu                 Linia_produktowa  \\\n",
       "0     31006967  2025-09-01          07:07               KAJZERKA xxl 95g-C   \n",
       "1     31006967  2025-09-01          07:07  SER TOPIONY TOST PLASTRY 130g-C   \n",
       "2     31006967  2025-09-01          07:07              CHLEB TOST PELNOZ-C   \n",
       "\n",
       "                                      Nazwa_produktu  Ilosc  \\\n",
       "0                                                NaN    2.0   \n",
       "1  Sertop Tychy Ser topiony w plastrach tost 130 ...    1.0   \n",
       "2                                                NaN    1.0   \n",
       "\n",
       "   Cena_jednostkowa_brutto  Cena_jednostkowa_netto  \n",
       "0                     0.79                    0.75  \n",
       "1                     6.40                    6.10  \n",
       "2                     4.99                    4.75  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 structure check (pre-normalization)\n",
    "drop_cols = [\"Numer_paragonu\",\"EAN\",\"Rabat\",\"Kasjer\",\"Metoda_platnosci\", \"Stawka_VAT\", \"Siec_sklepow\"]\n",
    "present = [c for c in drop_cols if c in df.columns]\n",
    "if present:\n",
    "    df = df.drop(columns=present)\n",
    "    print(\"Dropped columns:\", present)\n",
    "else:\n",
    "    print(\"No useless columns to drop.\")\n",
    "    \n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(\"Raw columns:\", list(df.columns))\n",
    "\n",
    "# Ensure column names are unique\n",
    "dup_cols = pd.Series(df.columns).value_counts()\n",
    "if (dup_cols > 1).any():\n",
    "    print(\"Duplicate column names:\", dup_cols[dup_cols > 1].to_dict())\n",
    "\n",
    "# Save raw header snapshot\n",
    "pd.Series(df.columns, name=\"raw_columns\").to_csv(OUT_DIR/\"_raw_columns.csv\", index=False)\n",
    "\n",
    "# Peek a few rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a27738b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized columns: ['receipt_id', 'purchase_date', 'purchase_time', 'product_line', 'product_name', 'qty', 'unit_price_gross', 'unit_price_net']\n",
      "Missing required columns: []\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "receipt_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "purchase_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "purchase_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_line",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_name",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "qty",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unit_price_gross",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unit_price_net",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "43cd1ace-7da6-4124-a1fe-3d3e242db99a",
       "rows": [
        [
         "0",
         "31006967",
         "2025-09-01",
         "07:07",
         "KAJZERKA xxl 95g-C",
         null,
         "2.0",
         "0.79",
         "0.75"
        ],
        [
         "1",
         "31006967",
         "2025-09-01",
         "07:07",
         "SER TOPIONY TOST PLASTRY 130g-C",
         "Sertop Tychy Ser topiony w plastrach tost 130 g (8 sztuk) ",
         "1.0",
         "6.4",
         "6.1"
        ],
        [
         "2",
         "31006967",
         "2025-09-01",
         "07:07",
         "CHLEB TOST PELNOZ-C",
         null,
         "1.0",
         "4.99",
         "4.75"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receipt_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_name</th>\n",
       "      <th>qty</th>\n",
       "      <th>unit_price_gross</th>\n",
       "      <th>unit_price_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31006967</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>07:07</td>\n",
       "      <td>KAJZERKA xxl 95g-C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31006967</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>07:07</td>\n",
       "      <td>SER TOPIONY TOST PLASTRY 130g-C</td>\n",
       "      <td>Sertop Tychy Ser topiony w plastrach tost 130 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31006967</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>07:07</td>\n",
       "      <td>CHLEB TOST PELNOZ-C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   receipt_id purchase_date purchase_time                     product_line  \\\n",
       "0    31006967    2025-09-01         07:07               KAJZERKA xxl 95g-C   \n",
       "1    31006967    2025-09-01         07:07  SER TOPIONY TOST PLASTRY 130g-C   \n",
       "2    31006967    2025-09-01         07:07              CHLEB TOST PELNOZ-C   \n",
       "\n",
       "                                        product_name  qty  unit_price_gross  \\\n",
       "0                                                NaN  2.0              0.79   \n",
       "1  Sertop Tychy Ser topiony w plastrach tost 130 ...  1.0              6.40   \n",
       "2                                                NaN  1.0              4.99   \n",
       "\n",
       "   unit_price_net  \n",
       "0            0.75  \n",
       "1            6.10  \n",
       "2            4.75  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 normalize columns + basic dtypes\n",
    "df = normalize_columns(df)  # standardize column names\n",
    "df = cast_basic_types(df)   # qty -> float, prices -> float, ean -> float/Int64, etc.\n",
    "\n",
    "print(\"Normalized columns:\", list(df.columns))\n",
    "df.dtypes.to_frame(\"dtype\").to_csv(OUT_DIR/\"_normalized_dtypes.csv\")\n",
    "\n",
    "# Required columns for this audit\n",
    "required = {\n",
    "    \"receipt_id\",\"purchase_date\",\"purchase_time\",\n",
    "    \"product_name\",\"product_line\",\"qty\",\"unit_price_gross\"\n",
    "}\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "print(\"Missing required columns:\", missing)\n",
    "\n",
    "df.dtypes.to_frame(\"dtype\").to_csv(OUT_DIR/\"_normalized_dtypes.csv\")\n",
    "\n",
    "# Quick sample\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7e99bd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': 260000,\n",
       " 'unique_receipt_ids': 123246,\n",
       " 'exact_duplicate_lines': 4340,\n",
       " 'dup_within_receipt': 5956}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 keys & duplicates\n",
    "report = {}\n",
    "report[\"rows\"] = len(df)\n",
    "report[\"unique_receipt_ids\"] = df[\"receipt_id\"].nunique() if \"receipt_id\" in df else None\n",
    "\n",
    "# Exact duplicate lines\n",
    "report[\"exact_duplicate_lines\"] = int(df.duplicated().sum())\n",
    "\n",
    "# Duplicates within same receipt_id + product_name + qty + price\n",
    "subset_cols = [c for c in [\"receipt_id\",\"product_name\",\"unit_price_gross\",\"qty\"] if c in df.columns]\n",
    "if subset_cols:\n",
    "    dup_within = df.duplicated(subset=subset_cols).sum()\n",
    "    report[\"dup_within_receipt\"] = int(dup_within)\n",
    "\n",
    "pd.DataFrame([report]).to_csv(OUT_DIR/\"audit_keys_duplicates.csv\", index=False)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71b176f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top NA columns:\n",
      "product_name        0.004088\n",
      "receipt_id          0.000000\n",
      "purchase_time       0.000000\n",
      "purchase_date       0.000000\n",
      "product_line        0.000000\n",
      "qty                 0.000000\n",
      "unit_price_gross    0.000000\n",
      "unit_price_net      0.000000\n",
      "dtype: float64\n",
      "Suspicious qty/price rows: 0\n"
     ]
    }
   ],
   "source": [
    "# 6 missingness & numeric sanity\n",
    "na_pct = df.isna().mean().sort_values(ascending=False)\n",
    "na_pct.to_csv(OUT_DIR/\"na_fraction_by_column.csv\", header=[\"na_fraction\"])\n",
    "print(\"Top NA columns:\")\n",
    "print(na_pct.head(10))\n",
    "\n",
    "# Suspicious qty/price\n",
    "bad = df[(df[\"qty\"] <= 0) | (df[\"unit_price_gross\"] <= 0)]\n",
    "print(\"Suspicious qty/price rows:\", len(bad))\n",
    "bad.head(3).to_csv(OUT_DIR/\"_suspicious_qty_price_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c5fa396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alonbenach/project/invoice-analysis/src/clean_utils.py:120: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\").dt.time\n",
      "/home/alonbenach/project/invoice-analysis/src/clean_utils.py:120: FutureWarning: Parsed string \"17:14 LN\" included an un-recognized timezone \"LN\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
      "  return pd.to_datetime(s, errors=\"coerce\").dt.time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS parsed: 0.463 | Range: 2025-01-09 00:00:00+01:00 → 2025-12-09 23:02:00+01:00\n"
     ]
    }
   ],
   "source": [
    "# 7 timestamp parsing + slots\n",
    "tz = yaml.safe_load((PROJECT_ROOT/\"config/slots.yaml\").read_text())[\"timezone\"]\n",
    "df = parse_timestamp(df, tz)\n",
    "df = assign_slots(df, PROJECT_ROOT/\"config/slots.yaml\")\n",
    "\n",
    "pct_ts = df[\"ts\"].notna().mean()\n",
    "dmin, dmax = df[\"ts\"].min(), df[\"ts\"].max()\n",
    "print(f\"TS parsed: {pct_ts:.3f} | Range: {dmin} → {dmax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a4ff786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "product_line:\n",
      "product_line\n",
      "BUTELKA ZYWIEC 0,5(1)    3531\n",
      "BUTELKA KOMPANIA 0(1)    3005\n",
      "NAPOJ MONSTER 0,5l-A     2102\n",
      "TORBA PAPIEROWA ZA-A     1490\n",
      "BUTELKA OKOCIM 0,5(1)    1467\n",
      "PIWO HARNAS JP 0,5-A     1386\n",
      "HOT DOG PAR Z SZYN-B     1346\n",
      "NAPOJ OSHEE 555ml-C      1234\n",
      "NAPOJ COCA 0,85l-A       1233\n",
      "TORBA PAP MALA-A         1218\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 8 categorical distributions\n",
    "def top_counts(col):\n",
    "    s = df[col].value_counts(dropna=False).head(25)\n",
    "    s.to_csv(OUT_DIR/f\"top_{col}.csv\", header=[\"count\"])\n",
    "    return s\n",
    "\n",
    "for c in [\"product_line\",\"payment_method\",\"cashier\"]:\n",
    "    if c in df.columns:\n",
    "        print(f\"\\n{c}:\")\n",
    "        print(top_counts(c).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f41185e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "product_line",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "line_value_gross",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5afc04a2-7528-45c8-879d-aaebf34dad53",
       "rows": [
        [
         "PIWO ZUBR-A",
         "24063.36"
        ],
        [
         "PAPIEROSY LM FIRST-A",
         "21667.66"
        ],
        [
         "PAPIEROSY WINSTON BLUE SUPER L-A",
         "21539.99099"
        ],
        [
         "PAP LxM FC BRIG SL-A",
         "19271.0"
        ],
        [
         "PIWO HARNAS JP 0,5-A",
         "18523.6"
        ],
        [
         "NAPOJ MONSTER 0,5l-A",
         "17775.48"
        ],
        [
         "PIWO 4-PAK TYSKI-A",
         "17058.94"
        ],
        [
         "PAPIEROSY LM BLUE KS-A",
         "16184.96"
        ],
        [
         "PAPIEROSY LxM FIRS-A",
         "14391.0"
        ],
        [
         "BUTELKA ZYWIEC 0,5(1)",
         "13969.02"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "product_line\n",
       "PIWO ZUBR-A                         24063.36000\n",
       "PAPIEROSY LM FIRST-A                21667.66000\n",
       "PAPIEROSY WINSTON BLUE SUPER L-A    21539.99099\n",
       "PAP LxM FC BRIG SL-A                19271.00000\n",
       "PIWO HARNAS JP 0,5-A                18523.60000\n",
       "NAPOJ MONSTER 0,5l-A                17775.48000\n",
       "PIWO 4-PAK TYSKI-A                  17058.94000\n",
       "PAPIEROSY LM BLUE KS-A              16184.96000\n",
       "PAPIEROSY LxM FIRS-A                14391.00000\n",
       "BUTELKA ZYWIEC 0,5(1)               13969.02000\n",
       "Name: line_value_gross, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 product health + value mix\n",
    "df[\"line_value_gross\"] = df[\"qty\"] * df[\"unit_price_gross\"]\n",
    "val_by_pl = df.groupby(\"product_line\")[\"line_value_gross\"].sum().sort_values(ascending=False).head(20)\n",
    "val_by_pl.to_csv(OUT_DIR/\"value_by_product_line_top20.csv\", header=[\"value_gross\"])\n",
    "save_bar(val_by_pl, \"Gross value by product_line (top 20)\", PLOTS/\"value_by_product_line_top20.png\")\n",
    "val_by_pl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30b434eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily rows: 12  Range: 2025-01-09 → 2025-12-09\n",
      "Outlier lines: 382\n"
     ]
    }
   ],
   "source": [
    "# 10 daily coverage + outliers\n",
    "daily = (df.dropna(subset=[\"ts\"])\n",
    "           .groupby(df[\"ts\"].dt.date)\n",
    "           .agg(lines=(\"product_name\",\"size\"),\n",
    "                value=(\"line_value_gross\",\"sum\"))\n",
    "           .reset_index())\n",
    "daily.to_csv(OUT_DIR/\"daily_lines_value.csv\", index=False)\n",
    "print(f\"Daily rows: {len(daily)}  Range: {daily['ts'].min()} → {daily['ts'].max()}\")\n",
    "\n",
    "# Outliers\n",
    "hi_price = df[\"unit_price_gross\"].quantile(0.999)\n",
    "hi_qty = df[\"qty\"].quantile(0.999)\n",
    "outliers = df[(df[\"unit_price_gross\"] > hi_price) | (df[\"qty\"] > hi_qty)]\n",
    "outliers.head(10).to_csv(OUT_DIR/\"_outlier_lines_sample.csv\", index=False)\n",
    "print(\"Outlier lines:\", len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cd0d764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mapping: /home/alonbenach/project/invoice-analysis/data/refs/auto_fc_mapping_from_menu.csv\n",
      "Line-level mapping coverage: 1.000\n",
      "Lines flagged as FC (auto):  0.062\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_line",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2967a0d6-6373-4498-ae0a-e89e5cf79ec5",
       "rows": [],
       "shape": {
        "columns": 2,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [product_line, product_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11 food Corner mapping and coverage\n",
    "# Use product_line as the canonical product identifier\n",
    "df[\"product_norm\"] = normalize_text(df[\"product_line\"])\n",
    "\n",
    "# Load canonical Food Corner menu\n",
    "canonical_path = PROJECT_ROOT / \"data\" / \"refs\" / \"zabka_food_corner_menu_canonical.csv\"\n",
    "canonical = pd.read_csv(canonical_path)\n",
    "\n",
    "# Run deterministic mapping\n",
    "mapping = map_fc_products(df, canonical, threshold=70)\n",
    "\n",
    "# Save mapping\n",
    "MAP_OUT = PROJECT_ROOT / \"data\" / \"refs\" / \"auto_fc_mapping_from_menu.csv\"\n",
    "mapping.to_csv(MAP_OUT, index=False)\n",
    "print(\"Saved mapping:\", MAP_OUT)\n",
    "\n",
    "# Join back for coverage stats\n",
    "mp = mapping[[\"product_norm\",\"is_food_corner_auto\",\"match_category\",\"best_match_item\",\"score\"]].drop_duplicates(\"product_norm\")\n",
    "joined = df.merge(mp, on=\"product_norm\", how=\"left\")\n",
    "\n",
    "# Coverage & FC share\n",
    "line_coverage = joined[\"is_food_corner_auto\"].notna().mean()\n",
    "fc_rate = (joined[\"is_food_corner_auto\"] == True).mean()  # treat NaN as non-FC\n",
    "coverage = float(line_coverage)  # for back-compat with Cell 12\n",
    "\n",
    "# Save numeric summary\n",
    "pd.DataFrame([{\n",
    "    \"line_coverage\": float(line_coverage),\n",
    "    \"fc_rate\": float(fc_rate),\n",
    "    \"threshold\": 70\n",
    "}]).to_csv(OUT_DIR / \"fc_coverage_summary.csv\", index=False)\n",
    "\n",
    "# Simple bar “gauges”\n",
    "save_bar(pd.Series({\"mapped\": line_coverage, \"unmapped\": 1 - line_coverage}),\n",
    "         \"Line-level mapping coverage\", PLOTS/\"fc_line_coverage.png\")\n",
    "save_bar(pd.Series({\"FC\": fc_rate, \"Non-FC\": 1 - fc_rate}),\n",
    "         \"Lines flagged as Food Corner (auto)\", PLOTS/\"fc_flag_rate.png\")\n",
    "\n",
    "print(f\"Line-level mapping coverage: {line_coverage:.3f}\")\n",
    "print(f\"Lines flagged as FC (auto):  {fc_rate:.3f}\")\n",
    "\n",
    "# Unmapped sample for quick review\n",
    "unmapped = joined.loc[joined[\"is_food_corner_auto\"].isna(),\n",
    "                      [\"product_line\",\"product_name\"]].drop_duplicates().head(50)\n",
    "unmapped.to_csv(OUT_DIR / \"fc_unmapped_examples.csv\", index=False)\n",
    "unmapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239bbb17",
   "metadata": {},
   "source": [
    "To be fixed:\n",
    "* False positives\n",
    "* Better sorting algo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invoices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
